---
title: "Reasoning with Uncertainty"
subtitle: "An Introduction to Decision-Making with Data"
format: 
  revealjs:
   theme: [default, presentation-theme.scss]
   slide-number: true
editor_options: 
 chunk_output_type: console
---

## The Decision-Making Process 

```{r}
#| label: setup
#| echo: false
#| warning: false
#| output: false

library(ggplot2)
library(dplyr)
library(tibble)
library(patchwork)
library(tidyr)
library(ggtext)
```

Every decision involves a **decision maker** who must choose one **action** from a set of alternatives. Each action is associated with a set of possible **outcomes** that depend on the true **state of the world**. 

## You're the CHRO. What do you do?

A competitor of yours was recently sued because their selection system was found to be unintentionally discriminating against a protected class---disparate impact. 

As the CHRO, you have to **decide** whether your selection system needs to be revised to ensure it's not causing disparate impact.

## Deciding to Revise the Selection System

+----------------------+------------------------------------------------+------------------------------------------+
|                      | Disparate Impact                               | No Disparate Impact                      |
+:====================:+:==============================================:+:========================================:+
| Revise System        | Social & Ethical Benefit / Less legal exposure | Large expenses / Other opportunity costs |
+----------------------+------------------------------------------------+------------------------------------------+
| Keep System          | Law suits / Societal Disutility / Hurt org.    | Invest in other projects                 |
+----------------------+------------------------------------------------+------------------------------------------+

: {tbl-colwidths="[28, 36, 36]"}

## Questions You'd Likely Have

- What are the chances our selection system is causing disparate impact? [**State Question**]
- Our only choices are to fully revise the selection system or not? [**Action Question**]
- What are the chances our choices will actually result in a beneficial outcome? [**Outcome Question**]
- **Do we have any data to help us!?**

## The Role of Data in Decision-Making

**When used appropriately**, data can be used to inform the decision-making process in many different ways: 

- Provide information about the most likely state
- Provide information about what actions to take and their impact
- Provide information about the outcomes that resulted from similar actions

## How Do We Use Data Appropriately? 

Data are full of uncertainty. To answer any of your questions, you will need to wrestle with questions around the significance and strength of effects:

- Is the hiring rate of the majority group **significantly** different from the hiring rate of the minority group?
- How much **larger/smaller** is the hiring rate of the majority group compared to that of the minority group? 

## Answering Questions Around Significance

To answer questions about the significance of an effect, we usually rely on a statistical framework called Null Hypothesis Significance Testing (NHST). 

In our example, we want to know if the majority hiring rate ($\mathit{p}_{maj}$) is significantly different than the minority hiring rate ($\mathit{p}_{min}$).

## Breaking Down the NHST Framework

The NHST can be separated into five different components:

1. Assumptions
2. Statistical Hypotheses
3. Test Statistic 
4. P-Value
5. Conclusion/Decision

## Assumptions: Rarely Checked, Likely Violated

A few things about statistical assumptions:

1. There are more than a few. 
2. They are likely violated. 
3. Thank the mathematical powers that be that they are fairly insensitive to most violations. 
4. If you want to make a data scientist sweat, ask them if they checked the model assumptions. 

## Statistical Hypotheses: Assuming the Null Just to Prove it False 

A statistical hypothesis is a statement about the population effect you are estimating that should logically connect to the decision being made.

- Null Hypothesis ($H_0$): A statement that the effect takes a specific value---usually 0.
- Alternative Hypothesis ($H_a$): A statement that the effect takes on a range of values---usually any value, but 0.

Under NHST, we only test the null hypothesis! 

## Setting Up the Null & Alternative Hypotheses 

The effect we are interested in is the difference in hiring rates: $\mathit{p}_{maj} - \mathit{p}_{min}$

- $H_0$: The majority group hiring rate is equal to the minority group hiring rate or $\mathit{p}_{maj} - \mathit{p}_{min}=0$.

- $H_a$: The majority group hiring rate does not equal the minority group hiring rate or $\mathit{p}_{maj} - \mathit{p}_{min} \neq 0$

## Building a Test Statistic

With our null hypothesis specified, we can now use the data to build our test statistic, $Z$. $Z$ tells us how many standard deviations our estimated effect falls from the mean of the null sampling distribution, which is specified by the null hypothesis. 


$$Z = \frac{\overbrace{(\mathit{p_{maj}} - \mathit{p_{min}})}^\text{Est. Effect} - \overbrace{0}^\text{Null Hyp.}}{\text{SE of Null Dist.}}$$

## The Null Sampling Distribution

Because the test statistic is created by standardizing the estimated effect using the mean and standard error specified by the null hypothesis, we can use the standard normal distribution for the sampling distribution. 

```{r}
#| label: null-sampling-distribution
#| fig-align: center

ggplot2::ggplot(
  data = NULL,
  ggplot2::aes(
    x = c(qnorm(.001, mean = 0, sd = 1), qnorm(.999, mean = 0, sd = 1))
  )
) + 
  ggplot2::geom_area(
    stat = "function",
    fun = dnorm,
    args = list(mean = 0, sd = 1),
    color = "#112D4E",
    fill = "#3F72AF",
    xlim = c(qnorm(.001, mean = 0, sd = 1), qnorm(.999, mean = 0, sd = 1))
  ) +
  ggplot2::geom_segment(
    ggplot2::aes(
      x = 0,
      xend = 0,
      y = 0,
      yend = dnorm(0)
    ),
    size = 1.25
  ) + 
  ggplot2::geom_segment(
    ggplot2::aes(
      x = 1.80,
      xend = 1.80,
      y = 0,
      yend = dnorm(1.80)
    ),
    lty = "dotted",
    size = 1.5
  ) +
  ggplot2::theme(
    plot.background = element_rect(fill = "#F9F7F7", colour = "#F9F7F7"),
    panel.background = element_rect(fill = "#F9F7F7"),
    axis.line.x = element_line(colour = "#3D3C42"),
    axis.line.y = ggplot2::element_blank(),
    panel.grid.minor = element_line(colour = "#F9F7F7"),
    panel.grid.major = element_line(colour = "#F9F7F7"),
    legend.text = ggplot2::element_blank(),
    legend.title = ggplot2::element_blank(),
    legend.position = "none",
    axis.ticks.y = ggplot2::element_blank(),
    axis.text.y = ggplot2::element_blank()
  ) + 
  ggplot2::scale_x_continuous(
    breaks = c(-2, 0, 1.80, 2),
    labels = c(-2, 0, 1.80, 2)
  ) +
  ggplot2::annotate(
    geom = "curve", x = 2.5, y = dnorm(1.80), xend = 1.87, yend = dnorm(2.3), 
    curvature = -.3, linewidth = 1, arrow = arrow(length = unit(3, "mm"))
  ) +
  ggplot2::annotate(geom = "text", x = 2.5, y = dnorm(1.75), label = "Test Stat.", hjust = "center",
                    fontface = "bold") +
  ggplot2::annotate(
    geom = "curve", x = -.70, y = dnorm(1.80), xend = -.07, yend = dnorm(2.3), 
    curvature = .3, linewidth = 1, arrow = arrow(length = unit(2, "mm"))
  ) +
  ggplot2::annotate(geom = "text", x = -.70, y = dnorm(1.75), label = "H0 Value", hjust = "center",
                    fontface = "bold") +
  ggplot2::labs(
    y = "",
    x = "Test Statistic (Z) Values"
  )
```

## P-Value: Pretty Confusing

The p-value is the probability of observing a test statistic as extreme or more, in either direction, than your test statistic **given that the null hypothesis is true**. We use the p-value to provide evidence against the thing we are assuming is true...

```{r}
#| label: p-value-area
#| fig-align: center

ggplot2::ggplot(
  data = NULL,
  ggplot2::aes(
    x = c(qnorm(.001, mean = 0, sd = 1), qnorm(.999, mean = 0, sd = 1))
  )
) + 
  ggplot2::geom_area(
    stat = "function",
    fun = dnorm,
    args = list(mean = 0, sd = 1),
    color = "#112D4E",
    fill = "#112D4E",
    xlim = c(qnorm(.001, mean = 0, sd = 1), -1.80)
  ) +
  ggplot2::geom_area(
    stat = "function",
    fun = dnorm,
    args = list(mean = 0, sd = 1),
    color = "#112D4E",
    fill = "#3F72AF",
    xlim = c(-1.80, 1.80)
  ) +
  ggplot2::geom_area(
    stat = "function",
    fun = dnorm,
    args = list(mean = 0, sd = 1),
    color = "#112D4E",
    fill = "#112D4E",
    xlim = c(1.80, qnorm(.999))
  ) +
  ggplot2::geom_segment(
    ggplot2::aes(
      x = 0,
      xend = 0,
      y = 0,
      yend = dnorm(0)
    ),
    size = 1.25
  ) +
  ggplot2::scale_x_continuous(
    breaks = c(-2, -1.80, 0, 1.80, 2),
    labels = c(-2, -1.80, 0, 1.80, 2)
  ) +
  ggplot2::theme(
    plot.background = element_rect(fill = "#F9F7F7", colour = "#F9F7F7"),
    panel.background = element_rect(fill = "#F9F7F7"),
    axis.line.x = element_line(colour = "#3D3C42"),
    axis.line.y = ggplot2::element_blank(),
    panel.grid.minor = element_line(colour = "#F9F7F7"),
    panel.grid.major = element_line(colour = "#F9F7F7"),
    legend.text = ggplot2::element_blank(),
    legend.title = ggplot2::element_blank(),
    legend.position = "none",
    axis.ticks.y = ggplot2::element_blank(),
    axis.text.y = ggplot2::element_blank()
  ) +
  ggplot2::labs(
    y = "",
    x = "Test Statistic (Z) Values"
  ) + 
  ggplot2::annotate(
    geom = "curve", x = 2.5, y = dnorm(1.80), xend = 2, yend = dnorm(2.3), 
    curvature = -.3, linewidth = 1, arrow = arrow(length = unit(3, "mm"))
  ) +
  ggplot2::annotate(geom = "text", x = 2.5, y = dnorm(1.75), label = "3.5% of area above 1.80", hjust = "center",
                    fontface = "bold") +
  ggplot2::annotate(
    geom = "curve", x = -2.5, y = dnorm(1.80), xend = -2, yend = dnorm(2.3), 
    curvature = .3, linewidth = 1, arrow = arrow(length = unit(3, "mm"))
  ) +
  ggplot2::annotate(geom = "text", x = -2.5, y = dnorm(1.75), label = "3.5% of area below -1.80", hjust = "center",
                    fontface = "bold") + 
  ggtext::geom_richtext(
    ggplot2::aes(
      x = 0,
      y = dnorm(0)/2,
      label = "P-Value = .07 <br> .035 + .035"
    )
  )
  
```

## Getting Comfortable with the P-Value

To calculate a p-value, you must be comfortable making the following assumptions:

1. The null hypothesis is true (weird, right?)
2. We can create a sampling distribution using the standard normal distribution

## Conclusion: Should I Reject my Null Hypothesis? 

You can think of the p-value as providing **evidence against the null hypothesis.** The smaller the p-value, the more evidence we have that the null hypothesis is not actually true---despite assuming it is true. 

But how much evidence do we need? 

## Enter Alpha---the Significance Level

Generally, there is an explicitly stated or implicitly assumed threshold that if the p-value falls under, then we have sufficient evidence to **reject the null hypothesis.**

The value of this threshold is called $\alpha$ and it is usually set at .05. 

```{r}
#| label: alpha-plot
#| fig-align: center

ggplot2::ggplot(
  data = NULL,
  ggplot2::aes(
    x = c(qnorm(.001, mean = 0, sd = 1), qnorm(.999, mean = 0, sd = 1))
  )
) + 
  ggplot2::geom_area(
    stat = "function",
    fun = dnorm,
    args = list(mean = 0, sd = 1),
    color = "#112D4E",
    fill = "#112D4E",
    xlim = c(qnorm(.001, mean = 0, sd = 1), qnorm(.025))
  ) +
  ggplot2::geom_area(
    stat = "function",
    fun = dnorm,
    args = list(mean = 0, sd = 1),
    color = "#112D4E",
    fill = "#3F72AF",
    xlim = c(qnorm(.025), qnorm(.975))
  ) +
  ggplot2::geom_area(
    stat = "function",
    fun = dnorm,
    args = list(mean = 0, sd = 1),
    color = "#112D4E",
    fill = "#112D4E",
    xlim = c(qnorm(.975), qnorm(.999))
  ) +
  ggplot2::geom_segment(
    ggplot2::aes(
      x = 0,
      xend = 0,
      y = 0,
      yend = dnorm(0)
    ),
    size = 1.25
  ) +
  ggplot2::geom_segment(
    ggplot2::aes(
      x = 1.80,
      xend = 1.80,
      y = 0,
      yend = dnorm(1.80)
    ),
    lty = "dotted",
    size = 1.5
  ) +
  ggplot2::scale_x_continuous(
    breaks = c(-2, 0, 1.80, 2),
    labels = c(-2, 0, 1.80, 2)
  ) +
  ggplot2::theme(
    plot.background = element_rect(fill = "#F9F7F7", colour = "#F9F7F7"),
    panel.background = element_rect(fill = "#F9F7F7"),
    axis.line.x = element_line(colour = "#3D3C42"),
    axis.line.y = ggplot2::element_blank(),
    panel.grid.minor = element_line(colour = "#F9F7F7"),
    panel.grid.major = element_line(colour = "#F9F7F7"),
    legend.text = ggplot2::element_blank(),
    legend.title = ggplot2::element_blank(),
    legend.position = "none",
    axis.ticks.y = ggplot2::element_blank(),
    axis.text.y = ggplot2::element_blank()
  ) +
  ggplot2::labs(
    y = "",
    x = "Test Statistic (Z) Values"
  ) + 
  ggplot2::annotate(
    geom = "curve", x = 2.6, y = dnorm(1.80), xend = 2.10, yend = dnorm(2.3), 
    curvature = -.3, linewidth = 1, arrow = arrow(length = unit(3, "mm"))
  ) +
  ggplot2::annotate(geom = "text", x = 2.6, y = dnorm(1.75), label = "Rejection Region", hjust = "center",
                    fontface = "bold") +
  ggplot2::annotate(
    geom = "curve", x = -2.60, y = dnorm(1.80), xend = -2.10, yend = dnorm(2.3), 
    curvature = .3, linewidth = 1, arrow = arrow(length = unit(3, "mm"))
  ) +
  ggplot2::annotate(geom = "text", x = -2.6, y = dnorm(1.75), label = "Rejection Region", hjust = "center",
                    fontface = "bold")
  
```

## Does the NHST Framework Work? 

An article titled: *"Abandon statistical significance"* has been cited 1,004 times since it was published---in 2019.

For reference, an article of arguably higher quality (😉) published in 2014 by LoPilato, Carter, & Wang has a **staggering** 31 cites...

## When Does the NHST Framework Fall Apart? 

When the data you are working with can be characterized as: 

- Noisy: A lot of measurement error
- Weak: Small effect sizes 
- Small: The number of observations (per group) is "small"

What does this mean about people data? 

## What Happens when NHST Falls Apart?

We start making statistical errors:

- **Statistical Decision Errors**: Type 1 & Type 2 Errors
- **Effect Size Errors**: Type S & Type M Errors

## Statistical Decision Errors

Statistical decision errors are made when we choose the wrong action based on our p-value:

+---------------------+--------------+--------------+
|                     | $H_0$ True   | $H_0$ False  |
+:===================:+:============:+:============:+
| Reject $H_0$        | Type 1 Error | Correct Dec. |
+---------------------+--------------+--------------+
| Do Not Reject $H_0$ | Correct Dec. | Type 2 Error |
+---------------------+--------------+--------------+

: {tbl-colwidths="[33, 33, 33]"}

## Effect Size Errors

Effect size errors are errors that are made when an estimated effect, deemed significant, is **quite different** from the true effect: 

- **Type S (Sign) Error**: The sign of a significant, estimated effect is opposite of the true effect
- **Type M (Magnitude) Error**: The value of a significant, estimated effect is far from the magnitude of the true effect

## Lets See a Simulated Example!

Some quick simulation parameters to keep in mind: 

- **True difference in hiring rates**: .04
- **Hiring Rate of Majority Group**: .34
- **Hiring Rate of Minority Group**: .30
- **Impact Ratio**: .30 / .34 = .88
- **Majority Group Size**: 5000
- **Minority Group Size**: 200

## When Data Misleads You

How do these statistical errors impact your decision to revise your organization's selection system? 

- **Type 1 Error**: Spend money on unnecessary updates 
- **Type 2 Error**: Continued discrimination / legal exposure
- **Type S Error**: False sense of security / Continued discrimination / legal exposure / different interventions
- **Type M Error**: Unnecessary sense of alarm which could result in taking the wrong actions

## Methods to Understand Error Rates

Conduct a **design analysis**:

- **Prospective Design Analysis**: Before undertaking your analysis, simulate your data and calculate error rates under a range of different settings
- **Retrospective Design Analysis**: After undertaking your analysis, simulate similar data using parameters that mirror your study

## Methods to Reduce Error Rates

**Power** is the probability of rejecting $H_0$ when it is false. By increasing the power of your study, you are able to reduce Type 2, Type S, and Type M error rates. 

To increase power, you can: 

- Increase your sample size
- Increase the strength of the effect size 
- Decrease the $\alpha$ level

## Sample Size, Power, & Error Rates 

```{r}
#| label: power-analysis-plot
#| fig-align: center
#| fig-width: 15
#| fig-height: 10

set.seed(404)

data_power <- 
  tibble::tibble(
    n_min = seq(1, 5000, len = 1000)
  ) |>
  tidyr::expand_grid(
    tibble::tibble(
      effect = c(.04, .12, .21)
    )
  ) |>
  dplyr::mutate(
    n_maj = 5000,
    p_min = .30,
    p_maj = effect + p_min,
    p_pool = (p_maj * n_maj + p_min * n_min) / (n_maj + n_min),
    se_pool = sqrt((p_pool * (1 - p_pool)) * (1/n_maj + 1/n_min)),
    se_maj = sqrt((p_maj * (1 - p_maj)) / n_maj),
    se_min = sqrt((p_min * (1 - p_min)) / n_min),
    se_alt = sqrt(se_maj^2 + se_min^2),
    power = pnorm(qnorm(.975)*(se_pool / se_alt) - (effect / se_alt), lower.tail = F) + pnorm(-qnorm(.975)*(se_pool / se_alt) - (effect / se_alt)),
    s_error = pnorm(-qnorm(.975)*(se_pool / se_alt) - (effect / se_alt)) / power,
    m_error = NA_real_
  )

for(i in 1:nrow(data_power)) {
  est <- rnorm(5000, mean = data_power$effect[i], sd = data_power$se_alt[i])
  cut_off <- qnorm(.975, mean = 0, sd = data_power$se_pool[i])
  exag_ratio <- mean(abs(est)[abs(est) > cut_off]) / data_power$effect[i]
  data_power$m_error[i] <- round(exag_ratio, 2)
}

power_plot <- 
  ggplot2::ggplot(
  data = data_power |>
    dplyr::mutate(
      label = dplyr::case_when(
        effect == .04 ~ ".04 - Small Effect",
        effect == .12 ~ ".12 - Medium Effect",
        TRUE ~ ".24 - Large Effect"
      )
    ), 
  ggplot2::aes(
    x = n_min,
    y = power
  )
) + 
  ggplot2::geom_line(
    linewidth = 1.2,
    color = "#3F72AF",
  ) +
  ggplot2::geom_hline(yintercept = .80, color = "#3F72AF", linetype = "dashed") +
  ggplot2::scale_x_continuous(
    breaks = c(seq(0, 5000, by = 500))
  ) +
  ggplot2::facet_grid(. ~ label) +
  ggplot2::scale_y_continuous(
    breaks = seq(0, 1, by = .10)
  ) +
  ggplot2::labs(
    x = "Minority Group Size",
    y = "Statistical Power",
    title = "Statistical Power when Majority Group Size is 5000"
  ) + 
  ggplot2::theme(
    plot.background = element_rect(fill = "#F9F7F7", colour = "#F9F7F7"),
    panel.background = element_rect(fill = "#F9F7F7"),
    axis.line.x = element_line(colour = "#3D3C42"),
    axis.line.y = ggplot2::element_blank(),
    panel.grid.minor = element_line(colour = "#F9F7F7"),
    panel.grid.major = element_line(colour = "#F9F7F7"),
    legend.text = ggplot2::element_blank(),
    legend.title = ggplot2::element_blank(),
    legend.position = "none"
  )

sign_plot <- 
  ggplot2::ggplot(
  data = data_power |>
    dplyr::filter(effect == .04) |>
    dplyr::group_by(effect, power) |>
    dplyr::slice_max(s_error), 
  ggplot2::aes(
    x = power,
    y = s_error
  )
) + 
  ggplot2::geom_line(
    linewidth = 1.2,
    color = "#3F72AF",
  ) +
  ggplot2::labs(
    x = "Power",
    y = "Type S Error Rate",
    title = "Type S Errors"
  ) + 
  ggplot2::theme(
    plot.background = element_rect(fill = "#F9F7F7", colour = "#F9F7F7"),
    panel.background = element_rect(fill = "#F9F7F7"),
    axis.line.x = element_line(colour = "#3D3C42"),
    axis.line.y = ggplot2::element_blank(),
    panel.grid.minor = element_line(colour = "#F9F7F7"),
    panel.grid.major = element_line(colour = "#F9F7F7"),
    legend.text = ggplot2::element_blank(),
    legend.title = ggplot2::element_blank(),
    legend.position = "none"
  )

magnitude_plot <- 
  ggplot2::ggplot(
  data = data_power |>
    dplyr::filter(effect == .04) |>
    dplyr::summarize(
      m_error = mean(m_error),
      .by = power
    ), 
  ggplot2::aes(
    x = power,
    y = m_error
  )
) + 
  ggplot2::geom_line(
    linewidth = 1.2,
    color = "#3F72AF",
  ) +
  ggplot2::scale_y_continuous(
    breaks = seq(1, 31, by = 5)
  ) +
  ggplot2::labs(
    x = "Power",
    y = "Exageration Ratio",
    title = "Type M Error"
  ) + 
  ggplot2::theme(
    plot.background = element_rect(fill = "#F9F7F7", colour = "#F9F7F7"),
    panel.background = element_rect(fill = "#F9F7F7"),
    axis.line.x = element_line(colour = "#3D3C42"),
    axis.line.y = ggplot2::element_blank(),
    panel.grid.minor = element_line(colour = "#F9F7F7"),
    panel.grid.major = element_line(colour = "#F9F7F7"),
    legend.text = ggplot2::element_blank(),
    legend.title = ggplot2::element_blank(),
    legend.position = "none"
  )

power_patchwork <- power_plot / (sign_plot | magnitude_plot)

power_theme <- 
  ggplot2::theme(
    plot.background = element_rect(fill = "#F9F7F7", colour = "#F9F7F7"),
    panel.background = element_rect(fill = "#F9F7F7"),
    axis.line.x = element_line(colour = "#3D3C42"),
    axis.line.y = ggplot2::element_blank(),
    panel.grid.minor = element_line(colour = "#F9F7F7"),
    panel.grid.major = element_line(colour = "#F9F7F7"),
    legend.text = ggplot2::element_blank(),
    legend.title = ggplot2::element_blank(),
    legend.position = "none"
  )

power_patchwork & power_theme
```

## Let the Data Inform Your Decision, Don't Let it Drive It

Decision-makers and those analyzing the data need to recognize that modeling uncertainty is **difficult** and full of **subjective decisions**.

It'd be better if we:

1. Focus on the effect, the uncertainty around it, and always keep in mind prior evidence
2. Use the tools being developed for causal inference 
3. Forget about binary statistical decisions---treat the p-value continuously


